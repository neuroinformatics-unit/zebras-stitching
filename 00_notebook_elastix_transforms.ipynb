{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:48:38.880972Z",
     "start_time": "2025-03-11T12:48:38.878555Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from brainglobe_registration.elastix.register import (\n",
    "    run_registration\n",
    ")\n",
    "from brainglobe_registration.utils.utils import open_parameter_file\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "63bce17e64769923",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:49:06.575796Z",
     "start_time": "2025-03-11T12:48:41.471697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6294, 1080, 1920)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "def load_video_to_numpy(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    \n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frames.append(frame.astype(np.uint8))\n",
    "    \n",
    "    cap.release()\n",
    "    return np.array(frames, dtype=np.uint8)\n",
    "\n",
    "video_path = 'videos/21Jan_007.mp4'\n",
    "video_data = load_video_to_numpy(video_path)\n",
    "print(video_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b28d6533e44fcc4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-07T14:55:53.388434Z",
     "start_time": "2025-03-07T14:55:53.384825Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ff402f34b100291",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T12:49:26.720796Z",
     "start_time": "2025-03-11T12:49:26.718447Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/wolf/NIU-dev/brainglobe-registration/brainglobe_registration/parameters/brainglobe_registration/affine.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      1\u001b[39m file_path = (\n\u001b[32m      2\u001b[39m     Path.home() / \u001b[33m\"\u001b[39m\u001b[33mNIU-dev\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mbrainglobe-registration\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      3\u001b[39m     / \u001b[33m\"\u001b[39m\u001b[33mbrainglobe_registration\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m      6\u001b[39m     / \u001b[33m\"\u001b[39m\u001b[33maffine.txt\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m parameter_lists = [(\u001b[33m\"\u001b[39m\u001b[33maffine\u001b[39m\u001b[33m\"\u001b[39m, \u001b[43mopen_parameter_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m)\u001b[49m)]\n\u001b[32m     10\u001b[39m parameter_lists[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mFixedInternalImagePixelType\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[33m\"\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     11\u001b[39m parameter_lists[\u001b[32m0\u001b[39m][\u001b[32m1\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mMovingInternalImagePixelType\u001b[39m\u001b[33m\"\u001b[39m] = [\u001b[33m\"\u001b[39m\u001b[33mfloat\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/git/zebras-stitching/.venv/lib/python3.12/site-packages/brainglobe_registration/utils/utils.py:108\u001b[39m, in \u001b[36mopen_parameter_file\u001b[39m\u001b[34m(file_path)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mopen_parameter_file\u001b[39m(file_path: Path) -> Dict:\n\u001b[32m     90\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     91\u001b[39m \u001b[33;03m    Opens the parameter file and returns the parameter dictionary.\u001b[39;00m\n\u001b[32m     92\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    106\u001b[39m \u001b[33;03m        A dictionary containing the parameters from the file.\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m    109\u001b[39m         param_dict = {}\n\u001b[32m    110\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m f.readlines():\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/Users/wolf/NIU-dev/brainglobe-registration/brainglobe_registration/parameters/brainglobe_registration/affine.txt'"
     ]
    }
   ],
   "source": [
    "file_path = (\n",
    "    Path.home() / \"NIU-dev\" / \"brainglobe-registration\"\n",
    "    / \"brainglobe_registration\"\n",
    "    / \"parameters\"\n",
    "    / \"brainglobe_registration\"\n",
    "    / \"affine.txt\"\n",
    ")\n",
    "\n",
    "parameter_lists = [(\"affine\", open_parameter_file(file_path))]\n",
    "parameter_lists[0][1][\"FixedInternalImagePixelType\"] = [\"float\"]\n",
    "parameter_lists[0][1][\"MovingInternalImagePixelType\"] = [\"float\"]\n",
    "parameter_lists[0][1][\"NumberOfResolutions\"] = [\"2\"]\n",
    "parameter_lists[0][1][\"MaximumNumberOfIterations\"] = [\"200\"]\n",
    "parameter_lists[0][1][\"Transform\"] = [\"EulerTransform\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a8c7fb2acf1195",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:35:14.053011Z",
     "start_time": "2025-03-11T12:49:36.584561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a08a61b5d88421097eddeb82480bc2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "output_file = \"out_euler_frame.csv\"\n",
    "\n",
    "with open(output_file, \"w\") as f:\n",
    "    f.write(\"theta,tx,ty\\n\")\n",
    "\n",
    "for i in tqdm(range(1, video_data.shape[0])):\n",
    "    fixed_gray = video_data[i-1]\n",
    "    moving_gray = video_data[i]\n",
    "    parameters = run_registration(\n",
    "        fixed_gray,\n",
    "        moving_gray,\n",
    "        parameter_lists,\n",
    "        filter_images=False\n",
    "    )\n",
    "\n",
    "    # Regular expression to find the TransformParameters line\n",
    "    pattern = r'\\(TransformParameters ([\\d\\.\\-e ]+)\\)'\n",
    "    input_string = str(parameters)\n",
    "    # Search for the pattern in the input string\n",
    "    match = re.search(pattern, input_string)\n",
    "\n",
    "    if match:\n",
    "        # Extract the numbers and convert them to floats\n",
    "        transform_parameters = list(map(float, match.group(1).split()))\n",
    "        with open(output_file, \"a\") as f:\n",
    "            f.write(\",\".join(map(str, transform_parameters)))\n",
    "            f.write(\"\\n\")\n",
    "    else:\n",
    "        print(\"TransformParameters not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e03dc0eb62ef2dac",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:49:52.549543Z",
     "start_time": "2025-03-11T13:49:52.543082Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "theta",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "tx",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "ty",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "ae956ffd-4ab2-4b16-86d6-34188e03cc3e",
       "rows": [
        [
         "0",
         "0.0",
         "0.0",
         "0.0"
        ],
        [
         "1",
         "2.45347e-05",
         "1.08235",
         "0.430159"
        ],
        [
         "2",
         "3.56711e-06",
         "1.19972",
         "0.422593"
        ],
        [
         "3",
         "7.97703e-05",
         "1.09691",
         "0.397563"
        ],
        [
         "4",
         "7.48648e-05",
         "1.13254",
         "0.432469"
        ]
       ],
       "shape": {
        "columns": 3,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>theta</th>\n",
       "      <th>tx</th>\n",
       "      <th>ty</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>1.08235</td>\n",
       "      <td>0.430159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000004</td>\n",
       "      <td>1.19972</td>\n",
       "      <td>0.422593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000080</td>\n",
       "      <td>1.09691</td>\n",
       "      <td>0.397563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000075</td>\n",
       "      <td>1.13254</td>\n",
       "      <td>0.432469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      theta       tx        ty\n",
       "0  0.000000  0.00000  0.000000\n",
       "1  0.000025  1.08235  0.430159\n",
       "2  0.000004  1.19972  0.422593\n",
       "3  0.000080  1.09691  0.397563\n",
       "4  0.000075  1.13254  0.432469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_file = \"data/elastix/out_euler_frame_masked.csv\"\n",
    "\n",
    "df = pd.read_csv(output_file)\n",
    "## Add the first frame row\n",
    "df = pd.concat([pd.DataFrame({\n",
    "    'theta': [0],\n",
    "    'tx': [0],\n",
    "    'ty': [0]\n",
    "}), df], ignore_index=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e1bc4432f7317914",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:49:58.062491Z",
     "start_time": "2025-03-11T13:49:58.060202Z"
    }
   },
   "outputs": [],
   "source": [
    "df['tx_sum'] = df['tx'].cumsum()\n",
    "df['ty_sum'] = df['ty'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "286e9d138fd5860b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:49:58.877089Z",
     "start_time": "2025-03-11T13:49:58.874298Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3871 -274 596\n"
     ]
    }
   ],
   "source": [
    "df['tx_sum_int'] = df['tx_sum'].round(0).astype(int)\n",
    "df['ty_sum_int'] = df['ty_sum'].round(0).astype(int)\n",
    "\n",
    "x_min = df['tx_sum_int'].min()\n",
    "x_max = df['tx_sum_int'].max()\n",
    "y_min = df['ty_sum_int'].min()\n",
    "y_max = df['ty_sum_int'].max()\n",
    "print(x_min, x_max, y_min, y_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bc7e1740cfec73d6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:50:31.889901Z",
     "start_time": "2025-03-11T13:50:31.887968Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1950 5791\n"
     ]
    }
   ],
   "source": [
    "height, width = video_data.shape[1:3]\n",
    "\n",
    "total_height = y_max - y_min + height\n",
    "total_width = x_max - x_min + width\n",
    "\n",
    "print(total_height, total_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e7b16a3192cdd2d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:51:39.424288Z",
     "start_time": "2025-03-11T13:51:38.641253Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "fused_image = np.zeros((total_height, total_width), dtype=np.uint8)\n",
    "\n",
    "for i in range(video_data.shape[0] - 1, 0, -1):\n",
    "    x = df['tx_sum_int'][i] - x_min\n",
    "    y = df['ty_sum_int'][i] - y_min\n",
    "    fused_image[y:y+height, x:x+width] = video_data[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802f54a0912e1e22",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-11T13:51:41.498546Z",
     "start_time": "2025-03-11T13:51:41.488817Z"
    }
   },
   "outputs": [],
   "source": [
    "import tifffile\n",
    "\n",
    "tifffile.imwrite(\"fused_image_masked.tif\", fused_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62faf8ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
